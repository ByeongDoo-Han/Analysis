{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tips of Data analysis](https://drive.google.com/file/d/12faqaslFIF-Sg_sU3jeGyauW5ClRqS8D/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data type for reduce memory\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "각 컬럼 내 데이터의 최소, 최대 범위를 계산해\n",
    "적절한 Data type을 찾아내는 함수\n",
    "\n",
    "각 컬럼의 데이터 형식을 모를 때 자동으로\n",
    "체크하여 사용하고 데이터를 불러올 때\n",
    "체크된 데이터 형식으로 데이터를 불러옵니다\n",
    "\n",
    "형식을 지정하지 않으면 가장 메모리를 많이 차지하는\n",
    "방식으로 데이터를 불러오기 때문에\n",
    "형식을 지정해서 데이터를 불러오면 메모리를 줄여\n",
    "큰 데이터도 불러올 수 있습니다\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "데이터 분석을 하다 보면 처리된 데이터를 따로 저장하거나 다른 사람에게 공유해야 될\n",
    "때가 많습니다\n",
    "\n",
    "일반적으로 사용하는 CSV 포맷의 단점\n",
    "\n",
    "- string 기반으로 IO 효율이 떨어짐\n",
    "- Meta data가 없어 각 컬럼의 데이터 형식 등에 대해 연속성을 가지고 사용 불가\n",
    "\n",
    "최근 많이 사용되고 있는 hdf5, parquet 포맷과 pickle, feather 같은 다른 포맷과\n",
    "1) 데이터를 읽고 쓰는 시간, 2) 메모리 사용량, 3) 저장된 파일의 크기를 비교할 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dtypes(file_path):\n",
    "    print(file_path)\n",
    "    tmp = pd.read_csv(file_path, nrows=0)\n",
    "    col_dtypes = {}\n",
    "    for col in tmp.columns:\n",
    "        df = pd.read_csv(file_path, usecols=[col])\n",
    "        dtype = df[col].dtype\n",
    "        \n",
    "        if dtype == 'int' or dtype == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "        elif dtype == 'object':\n",
    "            n_unique = df[col].nunique()\n",
    "            threshold = n_unique / df.shape[0]\n",
    "            \n",
    "        if dtype == 'int':\n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                col_dtype = 'int8'\n",
    "            elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n",
    "                col_dtype = 'uint8'\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                col_dtype = 'int16'\n",
    "            elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n",
    "                col_dtype = 'uint16'\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                col_dtype = 'int32'    \n",
    "            elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n",
    "                col_dtype = 'uint32'\n",
    "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                col_dtype = 'int64' \n",
    "            elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n",
    "                col_dtype = 'uint64'\n",
    "                \n",
    "        elif dtype == 'float':\n",
    "#            # ERROR occured When using float32 in feather, parquet\n",
    "#            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                col_dtype = 'float16'\n",
    "            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                col_dtype = 'float32'\n",
    "            else:\n",
    "                col_dtype = 'float64'\n",
    "        \n",
    "        elif dtype == 'object':\n",
    "            if threshold > 0.7:\n",
    "                col_dtype = 'object'\n",
    "            else:\n",
    "                col_dtype = 'category'\n",
    "        \n",
    "        col_dtypes[col] = col_dtype\n",
    "    \n",
    "    return col_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_health(patient):\n",
    "    \n",
    "    bmi = ((patient['Weight'] / (patient['Height']/100**2) >= 30)) * 1\n",
    "    waist = (patient['WAIST'] >= 90) * 1\n",
    "    blds = (patient['BLDS'] >= 125) * 1\n",
    "    chole = (patient['TOT_CHOLE'] >= 130) * 1\n",
    "    trigly = (patient['TRIGLYCERIDE'] >= 150) * 1\n",
    "    hmg = (patient['HMG'] < 12) * 1\n",
    "    crea = (patient['CREATININE'] > 1.7) * 1\n",
    "    sg = ((patient['SGOT_AST'] >= 40) | (patient['SGPT_ALT'] >= 40)) * 1\n",
    "    smoke = (patient['SMOKE'] == 3) * 1\n",
    "    drink = (patient['DRINK'] == 1) * 1\n",
    "\n",
    "    patient_score = np.sum([bmi, waist, blds, trigly, hmg, crea, sg, smoke, drink], axis=0)\n",
    "\n",
    "    return patient_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration by indexing with len(df)\n",
    "\n",
    "\"\"\"\n",
    "scores = []\n",
    "for i in range(len(df)):\n",
    "patient = df.iloc[i]\n",
    "scores.append(scoring_health(patient))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration by using .iterrows()\n",
    "\n",
    "\"\"\"\n",
    "scores = []\n",
    "for patient in df.iterrows():\n",
    "scores.append(scoring_health(patient))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas.apply()\n",
    "\n",
    "\"\"\"\n",
    "scores = df.apply(scoring_health, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization with Pandas Series\n",
    "\n",
    "\"\"\"\n",
    "scores = scoring_health(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization with Numpy Array\n",
    "\n",
    "\"\"\"\n",
    "scores = scoring_health_np(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tmp = t20['EDEC_TRAMT'].sort_values(ascending=False).head(5)\n",
    "\n",
    "tmp = t20[\"EDEC_TRAMT\"].nlargest(5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Comprehension\n",
    "\n",
    "\"\"\"\n",
    "df = df[[x in patients for x in df[‘PATIENT_ID’]]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series.apply()\n",
    "\n",
    "\"\"\"\n",
    "df = df[df['PATIENT_ID'].apply(lambda x: x in patients)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.isin()\n",
    "\n",
    "\"\"\"\n",
    "df = df[df.isin({‘PATIENT_ID’: patients})[‘PATIENT_ID’]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.query()\n",
    "\n",
    "\"\"\"\n",
    "df = df.query(‘PATIENT_ID in @patients’)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.isin()\n",
    "\n",
    "\"\"\"\n",
    "df = df[np.isin(df[‘PATIENT_ID’], patients)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.merge()\n",
    "\n",
    "\"\"\"\n",
    "df = df.merge(patients, how=‘inner’, on=‘PATIENT_ID’)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inplace\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* “inplace” parameter는 Pandas DataFrame에서 작업을 하다가 결과를 바로 해당\n",
    "DataFrame에 덮어씌우고 싶을 때 많이 사용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inplace를 왜 사용하는가, 왜 사용하지 말아야 하는가?\n",
    "\n",
    "inplace를 선호하는 사용자들의 여러 의견은 다음과 같습니다\n",
    "\n",
    "- 속도가 더 빠르다\n",
    "\n",
    "- 메모리를 더 효율적으로 사용한다\n",
    "\n",
    "이에 Pandas Core 개발자들은 반대를 하고 있으며,\n",
    "이미 inplace parameter에 대한 deprecation 및 삭제를 논의하고 있고,\n",
    "Method Chaining 방식을 적극 권장하고 있습니다\n",
    "\n",
    "inplace 실행 이후에도 메모리에 데이터가 남아있는 문제가 자주 있기 때문입니다\n",
    "___\n",
    "\n",
    "### 어떤식으로 구분해서 사용하는 것이 좋은가\n",
    "\n",
    "a. Method Chaining\n",
    "\n",
    "- 결과 DataFrame의 전체를 생성하고 재할당(reassign)하는 특징\n",
    "- chaining 과정에서 데이터가 크기가 줄어들 때 메모리 효율적\n",
    "- 따라서 .drop(), .astype() 등을 우선적으로 사용하는 것이 좋음\n",
    "\n",
    "b. inplace parameter\n",
    "\n",
    "- 추상화된 함수 내부에서 DataFrame의 일부만 생성되어 재할당(reassign)되는 특징\n",
    "- 큰 작업 단위에서 Method Changing 보다 성능, 메모리 사용에서 종종 우위를 보임\n",
    "- 따라서 .set_index(), .rename() 과 같이 일부 내용만 변경하는 경우에 효율적\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Scaling?\n",
    "1. Buy more RAM...\n",
    "2. Other Dataframe frameworks\n",
    "\n",
    "- Dask, Modin\n",
    "\n",
    "3. GPU\n",
    "\n",
    "- Numba, cuDF\n",
    "\n",
    "4. Parallelization module\n",
    "\n",
    "- multiprocessing\n",
    "5. DBMS, Spark ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
